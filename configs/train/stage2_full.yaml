data:
  root_dir: './data/vox1_png'
  sample_size:  [512, 512]
  sample_stride: 1
  sample_n_frames: 16
  id_sampling: True

solver:
  gradient_accumulation_steps: 1
  mixed_precision: fp16  # AMP용
  fp16_mode: True        # FP16-only 모드 여부
  enable_xformers_memory_efficient_attention: False # unet_motion_model에서 작동x 
  gradient_checkpointing: True 
  max_train_steps: 20000  # (비디오 수*epoch)/(train_bs*gpu 수)=max_train_steps
  max_grad_norm: 1.0
  num_repeats: 75

  # lr
  learning_rate: 1e-5
  scale_lr: False 
  lr_warmup_steps: 1
  lr_scheduler: 'constant'

  # optimizer
  use_8bit_adam: True 
  adam_beta1: 0.9
  adam_beta2: 0.999
  adam_weight_decay:  1.0e-2
  adam_epsilon: 1.0e-8

val:
  validation_steps: 500
  validation_steps_tuple: [1, 10, 20, 50, 80]

noise_scheduler_kwargs:
  num_train_timesteps: 1000
  beta_start:          0.00085
  beta_end:            0.012
  beta_schedule:       "linear"
  steps_offset:        1
  clip_sample:         false

base_model_path: './pretrained_model/stable-diffusion-v1-5'
vae_model_path: './pretrained_model/sd-vae-ft-mse'
image_encoder_path: './pretrained_model/image_encoder'
motion_adapter_path: './pretrained_model/animatediff'

denoising_unet_path: "./exp_output/stage2/denoising_unet-40000.pth"
appearance_unet_path: "./exp_output/stage1/appearance_unet-100000.pth"
lia_model_path: "./exp_output/stage1/lia-100000.pth"

train_bs: 4

weight_dtype: 'fp16'  # [fp16, fp32]
uncond_ratio: 0.1
noise_offset: 0.05
snr_gamma: 5.0
enable_zero_snr: True 

# Loss weights
l1_scale: 1
vgg_scale: 0.1

time_threshold: 700

seed: 12580
resume_from_checkpoint: ''      # latest
checkpointing_steps: 4000
save_model_epoch_interval: 1
exp_name: 'stage2_full'
output_dir: './exp_output' 
